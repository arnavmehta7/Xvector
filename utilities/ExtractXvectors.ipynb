{"nbformat":4,"nbformat_minor":5,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.9"},"papermill":{"default_parameters":{},"duration":5087.161121,"end_time":"2021-04-03T04:07:24.219332","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2021-04-03T02:42:37.058211","version":"2.3.2"},"widgets":{"application/vnd.jupyter.widget-state+json":{}},"colab":{"name":"ExtractXvectors.ipynb","provenance":[],"collapsed_sections":[]}},"cells":[{"cell_type":"code","metadata":{"execution":{"iopub.execute_input":"2021-04-03T02:42:42.196602Z","iopub.status.busy":"2021-04-03T02:42:42.196086Z","iopub.status.idle":"2021-04-03T02:44:11.310624Z","shell.execute_reply":"2021-04-03T02:44:11.310048Z"},"id":"listed-feature","papermill":{"duration":89.140724,"end_time":"2021-04-03T02:44:11.310801","exception":false,"start_time":"2021-04-03T02:42:42.170077","status":"completed"},"tags":[],"outputId":"512e27ad-662d-491d-8592-ce56baec215b"},"source":["# Download voxconverse dataset\n","!wget --load-cookies /tmp/cookies.txt --no-verbose \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate --no-verbose 'https://docs.google.com/uc?export=download&id=1jkmsypHYrljIlDuuCfe2vABez1Own5r9' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=1jkmsypHYrljIlDuuCfe2vABez1Own5r9\" -O voxconverse_dev_wav.zip && rm -rf /tmp/cookies.txt\n","\n","# Unzip data files\n","!unzip -o -q voxconverse_dev_wav.zip -d ./\n","\n","# Remove zip file\n","!rm voxconverse_dev_wav.zip\n","\n","# Pull labels from github\n","!git clone https://github.com/joonson/voxconverse.git\n","\n","!pip install torchaudio -q --no-deps\n","!pip install speechbrain -q\n","!pip install spectralcluster -q\n","!pip install pyannote.metrics -q"],"id":"listed-feature","execution_count":null,"outputs":[{"output_type":"stream","text":["2021-04-03 02:42:56 URL:https://doc-00-4o-docs.googleusercontent.com/docs/securesc/8l3emp0v66elkaobmj3gg2n9t2f5a4bl/9p1mnh3phi0ipapa1a1sbsvshh1tqp14/1617417750000/03361959783973937060/00606084443186867714Z/1jkmsypHYrljIlDuuCfe2vABez1Own5r9?e=download&nonce=psuvgj7n34v9o&user=00606084443186867714Z&hash=jv3dju09mhcgf20ecoa98oo054nn1j9s [1988647478] -> \"voxconverse_dev_wav.zip\" [1]\r\n","Cloning into 'voxconverse'...\r\n","remote: Enumerating objects: 224, done.\u001b[K\r\n","remote: Counting objects: 100% (224/224), done.\u001b[K\r\n","remote: Compressing objects: 100% (84/84), done.\u001b[K\r\n","remote: Total 224 (delta 140), reused 224 (delta 140), pack-reused 0\u001b[K\r\n","Receiving objects: 100% (224/224), 97.46 KiB | 891.00 KiB/s, done.\r\n","Resolving deltas: 100% (140/140), done.\r\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"execution":{"iopub.execute_input":"2021-04-03T02:44:11.346712Z","iopub.status.busy":"2021-04-03T02:44:11.345881Z","iopub.status.idle":"2021-04-03T02:44:30.490720Z","shell.execute_reply":"2021-04-03T02:44:30.490243Z"},"id":"aerial-apartment","papermill":{"duration":19.171741,"end_time":"2021-04-03T02:44:30.490892","exception":false,"start_time":"2021-04-03T02:44:11.319151","status":"completed"},"tags":[],"outputId":"81fc0c24-55c6-4ef0-c2af-2bee46f523f3","colab":{"referenced_widgets":["248aa5c0904a4bb29879f29fa3c9fd4f","fda9bb4af9f34586ac6a1d6a8701e3ea","6c24934dcfec44a9bd50fb306104f077"]}},"source":["from __future__ import print_function, division\n","\n","import os\n","import torch\n","import torchaudio\n","import numpy as np\n","import pandas as pd\n","from torchvision import transforms\n","from torch.utils.data import Dataset, DataLoader\n","from speechbrain.pretrained import SpeakerRecognition\n","import torch.nn.functional as F\n","import matplotlib.pyplot as plt\n","\n","from pyannote.database.util import load_rttm\n","from pyannote.metrics.diarization import DiarizationErrorRate\n","\n","import warnings\n","warnings.filterwarnings('ignore')\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# Load ECAPA-TDNN x-vector based pre-trained model on speaker verification task (latest x-vector system)\n","# https://arxiv.org/pdf/2005.07143.pdf\n","ECAPA = SpeakerRecognition.from_hparams(source=\"speechbrain/spkrec-ecapa-voxceleb\", run_opts={\"device\": device})\n","\n","# Load VAD Model\n","# https://github.com/snakers4/silero-vad\n","model, utils = torch.hub.load(repo_or_dir='snakers4/silero-vad',\n","                              model='silero_vad',\n","                              force_reload=True)\n","(get_speech_ts, _, read_audio, _, _, _) = utils\n","\n","# Data pipeline\n","class DiarizationDataSet(Dataset):\n","    def __init__(self, \n","                 root_dir='../content/audio/', \n","                 label_dir='../content/voxconverse/dev/', \n","                 sr=16000, \n","                 window_len=240, \n","                 window_step=120, \n","                 transform=None,\n","                 batch_size_for_ecapa=512,\n","                 vad_step=4):\n","        \n","        \"\"\"\n","        Args:\n","        - root_dir (string): Local directory of the audio files\n","        - audioFilelist (string): txt file with audio file list\n","        - label_dir (string): Local directory of the rttm label files\n","        - sr (int): Sample rate for audio signal, default 16kHz\n","        - window_len (int): Length of each segment of audio signal in milliseconds\n","        - window_step (int): Length between two window_len in milliseconds\n","        - mel_transform (callable, optional): Parameters of mel transform. None signifies no transform\n","        - batch_size_for_ecapa (int): Size of batches used while applying pretrained speechbrain ECAPA model\n","\n","        \"\"\"\n","\n","        self.root_dir = root_dir\n","        self.filelist = sorted(os.listdir(root_dir))\n","        self.label_dir = label_dir\n","        self.sr = sr\n","        self.win_len = window_len\n","        self.win_step = window_step\n","        self.transform = transform\n","        self.batch_size_for_ecapa = batch_size_for_ecapa\n","        self.vad_step = vad_step\n","\n","    def __len__(self):\n","        return len(self.filelist)\n","  \n","    def __getitem__(self, idx):\n","        if torch.is_tensor(idx):\n","            idx = idx.tolist()\n","\n","        audio_path = os.path.join(self.root_dir, self.filelist[idx])\n","        label_path = os.path.join(self.label_dir, self.filelist[idx][:-4]+'.rttm')\n","\n","        # Torch array of audio signal\n","        audio = read_audio(audio_path, target_sr=self.sr)\n","\n","        if self.transform:\n","            audio = self.transform(audio.detach().cpu().numpy())\n","\n","        # Window len and Window step in frames\n","        win_len = self.win_len*(self.sr//1000)\n","        win_step = self.win_step*(self.sr//1000)\n","\n","        # Pad and create audio segments\n","        audio_vec = audio.reshape(1, audio.shape[0])\n","        audio_vec = F.pad(input=audio_vec, pad=(win_len//2, win_len//2, 0, 0), mode='constant', value=0)\n","\n","        audio_segments = []\n","        for i in range(win_len//2, audio_vec.shape[1]-win_len//2, win_step):\n","            audio_segments.append(audio_vec[:, i-win_len//2:i+win_len//2])\n","\n","        audio_segments = torch.vstack(audio_segments)\n","\n","        # Compute ECAPA-TDNN x-vectors for the audio signal\n","        Xt = []\n","        for i in range(audio_segments.shape[0]//self.batch_size_for_ecapa):\n","            Xt.append(ECAPA.encode_batch(audio_segments[i*self.batch_size_for_ecapa:(i+1)*self.batch_size_for_ecapa])[:,0,:])\n","\n","        if audio_segments.shape[0]%self.batch_size_for_ecapa != 0:\n","            Xt.append(ECAPA.encode_batch(audio_segments[(audio_segments.shape[0]//self.batch_size_for_ecapa)*self.batch_size_for_ecapa:])[:,0,:])\n","\n","        audio_segments = torch.vstack(Xt)\n","\n","        return audio_segments, label_path"],"id":"aerial-apartment","execution_count":null,"outputs":[{"output_type":"stream","text":["/opt/conda/lib/python3.7/site-packages/torchaudio/backend/utils.py:54: UserWarning: \"sox\" backend is being deprecated. The default backend will be changed to \"sox_io\" backend in 0.8.0 and \"sox\" backend will be removed in 0.9.0. Please migrate to \"sox_io\" backend. Please refer to https://github.com/pytorch/audio/issues/903 for the detail.\n","  '\"sox\" backend is being deprecated. '\n"],"name":"stderr"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"248aa5c0904a4bb29879f29fa3c9fd4f","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/1.20k [00:00<?, ?B/s]"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"fda9bb4af9f34586ac6a1d6a8701e3ea","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/83.3M [00:00<?, ?B/s]"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6c24934dcfec44a9bd50fb306104f077","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/1.92k [00:00<?, ?B/s]"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Downloading: \"https://github.com/snakers4/silero-vad/archive/master.zip\" to /root/.cache/torch/hub/master.zip\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"execution":{"iopub.execute_input":"2021-04-03T02:44:30.515423Z","iopub.status.busy":"2021-04-03T02:44:30.514873Z","iopub.status.idle":"2021-04-03T02:44:30.518238Z","shell.execute_reply":"2021-04-03T02:44:30.517724Z"},"id":"portuguese-baseball","papermill":{"duration":0.017272,"end_time":"2021-04-03T02:44:30.518344","exception":false,"start_time":"2021-04-03T02:44:30.501072","status":"completed"},"tags":[]},"source":["audio_dataset = DiarizationDataSet(root_dir='audio/',\n","                                   label_dir = 'voxconverse/dev/',\n","                                   sr = 16000, window_len = 1500, \n","                                   window_step = 750,\n","                                   transform = None,\n","                                   batch_size_for_ecapa=512)"],"id":"portuguese-baseball","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"execution":{"iopub.execute_input":"2021-04-03T02:44:30.541944Z","iopub.status.busy":"2021-04-03T02:44:30.541089Z","iopub.status.idle":"2021-04-03T02:44:31.210254Z","shell.execute_reply":"2021-04-03T02:44:31.208731Z"},"id":"appreciated-colon","papermill":{"duration":0.682461,"end_time":"2021-04-03T02:44:31.210391","exception":false,"start_time":"2021-04-03T02:44:30.527930","status":"completed"},"tags":[]},"source":["!mkdir VoxConverse_Xvectors"],"id":"appreciated-colon","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"execution":{"iopub.execute_input":"2021-04-03T02:44:31.259452Z","iopub.status.busy":"2021-04-03T02:44:31.258548Z","iopub.status.idle":"2021-04-03T04:05:21.970258Z","shell.execute_reply":"2021-04-03T04:05:21.969324Z"},"id":"changed-courtesy","papermill":{"duration":4850.750214,"end_time":"2021-04-03T04:05:21.970381","exception":false,"start_time":"2021-04-03T02:44:31.220167","status":"completed"},"tags":[],"outputId":"4478b84f-a53f-4f39-daab-fdfcf6f5b77d","colab":{"referenced_widgets":["5241738874344cc38441b91076eb947f"]}},"source":["from tqdm.auto import tqdm\n","\n","for i in tqdm(range(len(audio_dataset))):\n","    audio_segments, rttm_path = audio_dataset[i]\n","    name = rttm_path.split(sep=\"/\")[-1][:-5]\n","    np.save(\"VoxConverse_Xvectors/\" + name + \".npy\", audio_segments.detach().cpu().numpy())"],"id":"changed-courtesy","execution_count":null,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5241738874344cc38441b91076eb947f","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/216 [00:00<?, ?it/s]"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"execution":{"iopub.execute_input":"2021-04-03T04:05:21.995533Z","iopub.status.busy":"2021-04-03T04:05:21.994851Z","iopub.status.idle":"2021-04-03T04:07:19.852186Z","shell.execute_reply":"2021-04-03T04:07:19.852640Z"},"id":"cardiac-distribution","papermill":{"duration":117.872636,"end_time":"2021-04-03T04:07:19.853130","exception":false,"start_time":"2021-04-03T04:05:21.980494","status":"completed"},"tags":[]},"source":["!zip -r -q VoxConverse_Xvectors_750_1500.zip VoxConverse_Xvectors\n","!rm -r VoxConverse_Xvectors"],"id":"cardiac-distribution","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"execution":{"iopub.execute_input":"2021-04-03T04:07:19.880719Z","iopub.status.busy":"2021-04-03T04:07:19.879995Z","iopub.status.idle":"2021-04-03T04:07:21.944490Z","shell.execute_reply":"2021-04-03T04:07:21.943999Z"},"papermill":{"duration":2.080106,"end_time":"2021-04-03T04:07:21.944609","exception":false,"start_time":"2021-04-03T04:07:19.864503","status":"completed"},"tags":[],"id":"tough-portal"},"source":["!rm -r ./voxconverse\n","!rm -r ./pretrained_checkpoints\n","!rm -r ./audio"],"id":"tough-portal","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"papermill":{"duration":0.011164,"end_time":"2021-04-03T04:07:21.966616","exception":false,"start_time":"2021-04-03T04:07:21.955452","status":"completed"},"tags":[],"id":"bored-resistance"},"source":[""],"id":"bored-resistance","execution_count":null,"outputs":[]}]}
